# GPT-2-Implementation
This Python notebook implements the GPT-2 architecture, as outlined in the book Build LLMs from Scratch and taught by Dr. Raj on the Vizuara AI YouTube channel.

# GPT-2 Architecture Implementation

This repository contains a Python notebook that implements the GPT-2 architecture from scratch, following the principles taught in the book **"Build LLMs from Scratch"** and the YouTube series by **Dr. Raj (Vizuara AI)**.

The goal of this project is to provide a clear, educational implementation of GPT-2, helping learners understand the inner workings of transformer-based language models.

## ðŸ“š Based On

- **Book:** *Build LLMs from Scratch*
- **Instructor:** Dr. Raj
- **Platform:** [Vizuara AI YouTube Channel](https://www.youtube.com/@vizuara)

## ðŸš€ Features

- Tokenization and vocabulary handling
- Positional embeddings
- Multi-head self-attention mechanism
- Layer normalization and residual connections
- Transformer blocks
- Logits projection for language modeling
- Training loop using PyTorch

